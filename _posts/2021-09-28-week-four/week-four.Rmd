---
title: "Week Four"
description: |
  Finishing up some notes on Williams, and McDowell on thick concepts.
author:
  - name: Brian Weatherson
    url: http://brian.weatherson.org
date: 09-27-2021
bibliography: ../../../articles/Rbib.bib
preview: johnmcdowell1.jpg
categories:
  - relativism
  - reflection
  - shapelessness
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 3
    number_sections: true
---

### Reflection and the Wrong Kind of Reasons

So one thing I thought felt badly wrong in Williams was his conviction that reflection on why you care about something, or conceive of things in a certain way, would undermine those cares or conceptions. I think this kind of reflection is frequently a good thing. And I think this because if you're a value pluralist, as I am and I think as Williams is, you have to think a lot about what happens when values conflict. If you're a real pluralist you'll think that some of these conflicts are irresolvable. But sometimes thinking through why you care about this or that, or why you use this or that classification, can show you that certain conflicts have clear resolutions.

So why might reflection be bad? Williams gives one reason - that they push you towards thinking in thin terms, and that's bad. I don't really buy either premise in that. But let's look at one other possibility. Reflection is bad because it **destroys** the original conception. What I didn't sufficiently notice in class was that there are two ways in which this might happen: **metaphysical** and **psychological**.

What we mostly talked about in class was the metaphysical version. On this route, the problem is that even if the reflection leaves your behavior unchanged, it won't be the same kind of virtue if it is motivated the wrong way. The example we talked about a bit was **love**. If you provide for your children solely because the best institutional design for child rearing involves small families, that's not really love, even if you provide for them as well as any other parent. 

I think that's probably right, though I think the word 'solely' in the last paragraph is doing a bit of work. But I wonder how many other thick concepts are like this. My intuitions might be off here, but I think love is a bit of an outlier. It's possible to genuinely develop the character traits of honesty, courage, or empathy, on purely selfish instrumentalist grounds, so it should be easy for those to survive reflection. So one question: are there attitudes/traits other than love that are metaphysically incompatible with reflection in the sense that it wouldn't really be the same attitude/trait if one realised that one only had it for indirect reasons? If not, that would put a pretty sharp limit on the metaphysical downsides of reflection.

But what I didn't talk about in class was the psychological version. That's possibly a bigger deal, and one I could have touched on more. Here's the kind of thing I have in mind. Michael Strevens's recent book _The Knowledge Machine_ is about the strange kind of hyper-empiricism that has dominated science for a long time now. As he sees it, and I think he's right, the kind of empiricism that is the dominant ideology in most branches of science is a really terrible epistemology. There are lots of good ways to know about the world, especially involving analogical reasoning, or appeals to simplicity, that go beyond the narrow empirical grounds that the dominant ideology allows. But, says Strevens, it is a good thing that this 'bad' ideology has taken hold. Because only certain kinds of empirical data are allowed as evidence in public discourse, people who come to believe things on other grounds are compelled to go find more evidence to back up their theories. Without this compulsion we wouldn't have anyone willing to make the very detailed empirical investigations that have revealed so much about the world. So the empiricist ideology is individually irrational, but collectively valuable.

Now there's a tension here, one that Strevens is aware of. The ideology only works if the vast majority of people internalise it. If everyone thought, "This doesn't make sense but it leads to good consequences so let's keep going", then fairly soon they'd stop doing the extra experiments, and the good consequences would stop. They'd start arguing that the ideology was only meant to be a general guide, and surely this case is one of the exceptions where it doesn't apply, and their pet theory should be endorsed without them having to traipse through a jungle or whatever to collect the data that clinched the case for it. But we want people traipsing through those jungles! In theory, one could reflectively endorse the empiricist ideology on consequentialist grounds and keep producing the good consequences. But in practice we know that ain't gonna happen. And you might worry that a lot of social norms are like that - if people in general were aware of why the norms produced good outcomes, they would be too willing to carve out exceptions to the norms in their own case, and the good outcomes would stop.

How worried should we be about this? I have no idea - it would require a much more detailed investigation into (a) what the norms of various communities are, (b) why those norms produce social benefits, and (c) what the psychological consequences would be of realising that the norms are grounded in these social benefits. I don't know the answers to those questions in anything like the right kind of detail, but I think they would produce a more anti-reflection approach than I was allowing in class.

### Relativism and Philosophy of Language

The orthodox approach to semantics involves a commitment to something like the correspondance theory of truth. Declarative sentences are (typically) true or false, and when they are true, this is because they correspond to how things are. That last sentence needs a lot of spelling out. How can a sentence correspond to anything, apart from another sentence? Well, a sentence has a **content**. And that content can be true or false relative to various things. What things? Well, those are the matter of how things are in the platitude.

But how are things? It helps to work through an example. Let S be the sentence _Brian is sitting_. We will write ⟦S⟧ for the content of that sentence - these weird double square brackets have become the standard way for expressing the function from sentences to their contents. Now we want S to be true if, and only if, Brian is indeed sitting when S is uttered. That last bit, when S is uttered, is important. S doesn't say that I always sit, just that I'm now sitting. How should we incorporate that into our theory.

One approach is to build the time into the content of the utterance. On this view ⟦S⟧~t~ is **Brian is sitting at t**, where t is the time the sentence was uttered. The subscript is to say that this is the content of S at t. On this view there is no such thing as _the_ content of S, since it has different contents at different times of utterance. Then 'how things are' is the entire world, from Big Bang to Big Crunch. Call the world w, for simplicity, because we'll use it a lot. And we'll write $\vDash_w ⟦S⟧_t$ - which you can read as saying that the content of S is true at w, to say that this content is true. This approach is called **eternalism**, which is an annoyingly polysemous term in philosophy. If ⟦S⟧~t~ is true, it is always true, hence the eternal. It's true even if I stand up, because ⟦S⟧~t~ includes a reference to a time, and I stand at a later time. To introduce one more technical term, the time is part of the **context**; something that affects what the content of a given utterance of the sentence is. 

Another approach is to build the time into how things are. On this approach the world does go from Big Bang to Big Crunch, but how things are doesn't just involve a world, it involves a time too. (If you like you can make this time metaphysically special - like on a spotlight view - but that's not part of the linguistic theory.) The content of ⟦S⟧ is just what it looks like: that Brian sits. But that very content is true at some times and false at others. We write this as $\vDash_{\langle w, t \rangle} ⟦S⟧$. This view is known as **temporalism**, because the things that are true or false are temporal entities, they change truth value over time. And to introduce another technical term, on this theory the **index** is the pair $\langle w, t \rangle$. The index is what the sentence is measured up against.

What is the difference between these views? There is a view that it's a purely notational difference, that we shouldn't care about which is right. But that's a minority view. Most philosophers think there is a big issue here. The problem is that there is less agreement about what exactly the big issue is. We want contents, the outputs of the $⟦⟧$ function to play some philosophical role. The problem is that there are too many possible roles for them to play. Here are five possibilities.

1. The contents of what we believe.
2. The contents of what we say (if you think we have independent grasp on this).
3. The contents of 'that'-clauses, especially in indirect speech reports.
4. The things we agree or disagree with when we agree/disagree with an assertion.
5. The things we retract when we no longer endorse our former assertions.

Sometimes these five considerations push in the same direction. So consider the sentence _I was born in Australia_. That's true when uttered by me, and false (I think) when uttered by anyone else here. But when I say it, you don't disagree with me. And you don't report me by saying "Brian said that I was born in Australia". For reasons like this, everyone agrees that who the speaker is is relevant to the **content** of an utterance involving a first-person pronoun, not to the **index**. It's not that I say something that's true relative to me and false relative to you. It's that I say something that's true full stop, even though had you uttered the same words, you would have said something false. That's for the simple reason that you would have said something different.

But sometimes these considerations come apart. In the temporalism/eternalism debate, some considerations push towards putting time into the index, and some into the content.  And so there's a debate here, but I'm not going to go deep into it.

Just one quick thing to note though. I've talked so far as if it is obvious that worlds go into indices. And I think it is obvious that's true. But not everyone agrees. Some philosophers have recently argued that worlds should go into contexts and hence into contents. So when I say "There is a famous detective that lives on Baker Street", that's false, but the same utterance would be true in Sherlock-Holmes-world. That's because, says orthodoxy, there is a proposition _That a famous detective lives on Baker Street_ which is false in our world and true in Sherlock-Holmes-world. But some philosophers think that just like times go into contents (given eternalism), worlds should go into contents too. So when I say "There is a famous detective that lives on Baker Street", I express the proposition _That a famous detective lives on Baker Street in w_, where w is a name for our world. As I said, I think this is an absurd view, but it's worth noting it is out there. Still, most people think that indices are non-trivial, and they include at least worlds.

A huge amount of work in philosophy, especially in the 2000s, was on questions around the nature of context and index. In particular, these three questions took up a lot of people's time and attention. (The first by far the most, then the second, and then the third.)

1. Which utterances are such that their truth is sensitive to context? A huge debate, one of the biggest of the 90s and 2000s, was about whether knowledge ascriptions were among them, with **contextualists** (about knowledge) saying that utterances like "Brian knows that cars exist" could be true in regular contexts, but false in 'sceptical contexts'. But this was merely one manifestation of a discipline wide search for context-sensitivity.
2. If utterances are sensitive in this way, is this because the context affects their content, or because it affects the index they are evaluated against?
3. If it does affect the index, does it do so in a uniform way, or are there some sentences that interact differently with indices to others?

Don't worry about the last - I've got it there for completeness. It's mostly because the most important figure in this whole debate, John MacFarlane, disagrees with the way I've set up the debate so far. And it would be misleading to write his view out of the picture, since he is really the most important figure in it. MacFarlane's view is particularly motivated by issues about retraction, but I'm going to set those issues aside, and mostly set the precise views of MacFarlane aside as well.

For an example of what's at stake at least in questions 1 and 2, imagine that we have with us an ancient Spartan who very helpfully speaks English. And now let _S_ be the sentence "Infanticide is wrong". We endorse that sentence, and the Spartan rejects it. Here are three possible philosophical takes on that dispute.

First, we could have an invariantist approach. One of us, presumably us, is right, and the other is wrong. This is the view that most moral realists take, though actually a lot of views that are not particularly realist could take it as well.

Second, we could have what I'd call a **contextualist** approach. When we say "Infanticide is wrong", we speak truly. But when the Spartan says "Infanticide is not wrong", he speaks truly as well. Why? Because our sentences have different contents. The content of our sentence is _That infanticide is wrong by contemporary standards_. And the content of the Spartan's sentence is _That infanticide is wrong by Spartan standards_. And those propositions are both true.

Third, we could have what I'd call a **relativist** approach. (Though note MacFarlane denies this is relativism; he calls this view 'non-indexical contextualism'.) Both we and the Spartan speak truly. But we also disagree, because we endorse the very proposition that the Spartan rejects. How is this possible? Well, the proposition we are disputing is only true relative to an ordered pair of a world and a moral standard. Relative to our world/standard, it is true; relative to the Spartan's, it is false. It's just like if I said "There is no famous detective living on Baker Street", that's true, even though it expresses the negation of a proposition that a person in Sherlock-Holmes-world can truly express. In a figurative sense, we and the Spartan live in different moral worlds, so our thoughts and talk can clash, without either being wrong.

This was a very long response to an argument Williams briefly makes against moral relativism. He thinks it is a problem for relativism that people in isolated moral communities won't know that there are other communities, and so won't know to relativise their moral talk. I think this is only a problem for moral _contextualism_, not moral relativism properly speaking. The real moral relativist, in the sense of the previous chapter, does not think that the moral utterances that people make are in any sense about moral communities, or standards, or anything of the sort. Rather, they think that the theory of truth for the (simple) propositions those utterances express, involves relativity to communities/standards. And they don't have to say that competent speakers need realise that, any more than competent speakers have to know anything about the physics of time in order to use tensed language.

### McDowell

I'm going to focus on sections 4 and 5 of McDowell's paper, though we can talk as much as people want about 1-3 as well. But I think a lot of the last two sections is relevant even if you don't buy the first three sections.

#### Section 4 - The Meta-Ethics Conundrum

McDowell presents this as an argument, but I think it's helpful to see the challenge presented in this section as a trilemma. It's a really interesting puzzle. When I was a grad student I sort of had the impression - based on what people around me were working on - that how it should be resolved it was one of the two most important questions in philosophy. (The other was what is mental representation. I still sort of think these are the important questions, but the field has obviously changed a lot in 25 years.) Anyway, here's the inconsistent triad.

1. Moral attitudes provide reasons.
2. Beliefs alone do not provide reasons.
3. Moral attitudes are beliefs.

McDowell presents it as an argument from 1 and 2 to the negation of 3. And he presents this as something like the master argument for non-cognitivism. I don't know if that's quite right, but it is one of the big motivations for non-cognitivism.

It's really worth noting how much this feels like a paradox. The three claims look inconsistent. And we can make them clearly inconsistent with a bit of tidying up. But they all look really plausible to me.

When you get a paradox like this, one thing I like to do is to see whether you get a clearer mental map of where philosophers in the area fit by putting them into one of the three boxes depending on which of the three they reject. But, as often is the case, that taxonomy can obscure as much as it enlightens.

One reason that it obscures is that some people might reject more than one of these claims, and so not get easily partitioned. I don't really like reasons talk, but I think the best translation of my view into reasons talk ends up saying that 1 and 2 are both false. I think one can believe that it is right to leave car bombs in city centers, and have no reason at all to leave car bombs in city centers. And I also think the fact that one believes that a particular action (say, leaving a car bomb in a city center) will kill children is a reason all by itself not to do it.

A second reason this taxonomy might obscure things is that the presentation is so snappy that it leaves plenty of space for disambiguation, and some philosophers will reject different lines on different disambiguations. So consider Foot's view, either the 1958 view we read last time or the slightly later view McDowell considers. Foot changed her views on various things, but on this point I think she stayed constant. I would naturally read Foot as denying 2. But McDowell reads her as denying 1. That's because he wants 'reason' here to mean _decisive reason_. And while Foot thinks that a belief like that some action is rude is, all by itself, a reason to not do an action, it isn't a decisive reason. Sometimes, rudeness is just what's called for. I'm bringing this up partially because McDowell does, but partially because it's a fairly general phenomenon. Once you set up a dilemma or trilemma or whatever, there will be lots of people whose response is, "Well those terms are a bit ambiguous, and on one way of reading it, I think that's the false one..."

A third reason, and here's where I don't know McDowell's approach to things as well as I might, is that this whole way of setting things up presupposes that attitudes provide reasons. This is more than a bit controversial. Ignore ethics for a second. Imagine that I think there is a fire in the corridor. Do I have a reason to flee the building? On one picture, yeah, if I think there's a fire the only reasonable thing to do is to get out of there. But on another picture, it depends. If there is a fire in the building, then the fire itself is the reason to flee. I might only have that as a reason if I believe (or even know) that the fire is there. But the attitude itself is not the reason; it's something like the possibility condition of that fact being a reason.

Now how do we restate the paradox on this way of thinking about reasons? It's a little tricky. I mean I guess you'll reject 1, accept 2, and then it's an open question what you do with 3. That's to say, once you go this route, it seems this kind of thinking can't help settle what kinds of things mental attitudes are.

So for today, let's set that picture aside, and assume that attitudes, and not just their contents, do actually provide reasons. This is probably the best line for non-cognitivists to take since it lets the argument McDowell floats get traction.

McDowell gives two reasons he thinks people believe 2 - the part of the trilemma he wants to reject - and then describes why both of them are bad. I think the first is very unfair, but the second does I think get at something real in philosophy, and McDowell is right to criticise it.

The first reason he offers is the 'hydraulic' theory of mind. I think the idea here is that mental states have to literally push and pull you around. In short, reasons are active. But beliefs are passive. You can have all the beliefs in the world and essentially be a library, that's just sitting there waiting for someone to do something with the information storied in you. So beliefs can't be the things that do the pushing around. Now this looks at best like it is an argument that beliefs alone can't be **motivating** reasons. And surely this is an argument about **justifying** reasons. So I'm not quite sure what's going on. But I suspect whatever force the active/passive argument has actually turns on the thing McDowell says next, which is really interesting.

McDowell thinks his opponent is moved by the consideration that a reason must make something (an action, another belief, etc) make sense from 'sideways on'. If A justifies B, then it should be clear and obvious that A justifies B. And that's the assumption that he (i.e., McDowell) wants to reject. For what it's worth, I think he's right that a lot of people do make this assumption. (At least, I think the claim he made in 1981 is true of a lot of philosophers 40 years later. But I suspect it was true back then too.) And I think this really does lead to some of the more significant mistakes in contemporary philosophy.

One kind of philosopher who expects this kind of 'sideways on' view is the one who thinks there can be purely formal conceptions of rationality, and presumably that these can be objectively determined. A lot of philosophers who identify rationality with some kind of expected utility maximisation might fall into this camp, though it depends on the details of just how they define utility. I suspect something like this view, at least a non-quantitative version, is what McDowell has in mind. His opponent thinks rationality is taking the means you believe are best to achieve your desires, or something like that. And so rationality, and hence conclusive reasons, require desires.

Personally I find the idea that these formal conceptions of rationality can give us the neutral account of reasons very implausible, though this may be for autobiographical reasons. When I was an undergrad, the main things I worked on were arguments for and against the uses of different logics. When I was a grad student, the main things I worked on were arguments for and against the uses of different theories of uncertainty and decision. The idea that these philosophical debates have some kind of clear resolution that can provide a fixed point in reasoning about reasons seems absurd; they are some of the hardest questions in philosophy. 

There is another kind of philosopher who agrees with McDowell about rejecting 2, but does so because they think that moral beliefs are incredibly special. So consider someone who has the Lutheran view that it is vitally important to follow one's conscience, which we identify with their beliefs about what is good/right. They will think that one belief and one belief only can provide reasons, namely a thin moral belief. Now why would you give moral beliefs this special place. For many of them, it's because they want this kind of neutral conception of rationality, and they think that privileging thin moral beliefs - over thick moral beliefs and over what's actually moral - is a way to get to neutrality. But it's really an absurd position. And while it agrees with McDowell on the trilemma, it's a long way from McDowell's positive view, which does not privilege thin moral beliefs in this way.

There are two natural kinds of ways to think that a view of reasons might reject the possibility of a 'sideways on', or neutral, understanding of what a reason is. One way is to say that various facts, such that an action would involve killing a child, just are reasons whether someone identifies them or not. Another is to say that thick concepts, like rudeness, provide reasons, whether or not someone has the concept, or cares about it. And both of these seem like pretty interesting options to me.

#### Section 5 - Non-Cognitivism and Grounding

There is a fascinating argument in section 5 that hadn't occurred to me, and I'm not sure has gotten as much attention in the literature as it might have. The expressivist thinks that predicating a thick concept requires doing two different things - asserting that the descriptive part obtains, and whatever else they think one does with the non-descriptive part. It is very hard, even for competent speakers, to specify just what it is they are asserting, and what it is they are endorsing/prescribing. That's surprising, but given all we've learned about how much people can not understand their own language, maybe it shouldn't be too surprising. But McDowell notes that there is a deeper worry here for the non-cognitivist.

The evaluative part of the predication should be, at least from the inside, grounded. And it should be, or at least feel, grounded in the descriptive part. Saying that someone is honest isn't just describing and praising them. It's praising them for having the feature that you're describing them as having. And even more than that, the praise isn't like when you praise an ice cream for being tasty. It's moral praise, which means it should be to some extent non-arbitrary.

McDowell's argument, as I read him, is that if the descriptive part can't be independently identified, then the non-arbitrariness condition won't be satisfied. And in fact we can say something stronger. The non-arbitrariness condition perhaps requires that we identify the descriptive property independently of the evaluative property. We can't just identify it as the descriptive property that I positively evaluate around here. That wouldn't be a solid enough grounding. It would feel really arbitrary.

But it's no easier for a fluent user of the thick concept to independently identify the descriptive part than it is for someone who doesn't understand the values to identify the descriptive part. And that kind of person cannot identify the descriptive part - that's the shapelessness worry from earlier in the paper. So if thick concepts work the way that the non-cognitivist/expressivist thinks they do, they should feel arbitrary to the fluent user. But they do not feel arbitrary in this way, so the non-cognitivist/expressivist is mistaken.

I think this is a really fascinating argument, though there are a lot of moving parts in it. Here's what I would say back if I were defending the anti-realist position.

Non-arbitrariness doesn't require that we provide a perfectly precise statement of why we value the thing that we value. Nor does it require that we provide a conclusive reason for valuing it. Even if we can't say precisely what the descriptive part of what honesty is, we might be able to get close enough, so say at least that all honest people are H, where H is some descriptive property. And even if someone being H isn't a conclusive reason for valuing/praising/approving them, it might be a sufficient reason. This is one of the tricky things about moral reasons - sufficient reasons might not be conclusive. (By a 'sufficient' reason, I mean that it is enough reason all by itself, in the absence of defeating extra reasons.) If you offer a sufficient reason for doing something, it certainly won't feel arbitrary.

So here's the view I'd offer. Even if the Wittgensteinian arguments work against the possibility of precisely identifying the descriptive component, they don't work against the possibility of getting 'near enough'. And in this case, near enough might be good enough, because it will be enough to satisfy the non-arbitrariness constraint. But I'd be interested in hearing what other people think of this argument.

